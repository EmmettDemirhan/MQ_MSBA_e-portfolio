{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics - Assignment 2  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written (text) solution provide your answer in Markdown in appropriate cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to use the print() function. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "- Assignment 2 extends Assignment 1 on credit card applications. \n",
    "\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME_TOTAL   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day(0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_application:  438557\n",
      "Number of rows in df_credit:  1048575\n",
      "Number of unique bank clients in df_application:  438510\n",
      "Number of unique bank clients in df_credit:  45985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Answer 1.1\n",
    "df_application = pd.read_csv('data/application_record.csv')\n",
    "df_credit = pd.read_csv('data/credit_record.csv')\n",
    "\n",
    "# Amswer 1.2\n",
    "print(\"Number of rows in df_application: \",   len(df_application))\n",
    "print(\"Number of rows in df_credit: \", len(df_credit))\n",
    "\n",
    "# Answer 1.3\n",
    "print(\"Number of unique bank clients in df_application: \", df_application['ID'].nunique())\n",
    "print(\"Number of unique bank clients in df_credit: \", df_credit['ID'].nunique())\n",
    "\n",
    "# Answer 1.4\n",
    "df = pd.merge(df_application, df_credit, on='ID', how='inner')\n",
    "\n",
    "# Answer 1.5 \n",
    "#Number of rows in df:\n",
    "#df.shape[0]\n",
    "#Number of unique clients in df:\n",
    "#df['ID'].nunique()\n",
    "#df['STATUS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Answer 1.2 \n",
    "* Number of rows in 'df_application' is 438557 and Number of rows in 'df_credit' is 1048575\n",
    "###### Answer 1.3\n",
    "* Number of unique bank clients in  'df_application' is 438510 and Number of unique bank clients in 'df_credit' is 45985\n",
    "###### Answer 1.5\n",
    "* Number of rows in 'df' is 777715\n",
    "* Number of unique clients in 'df' is 36457\n",
    "\n",
    "###### Answer 1.6\n",
    "* Because we merged the two data frames, the multiple rows for each ID in df indicate that there are multiple records for each client that represent their monthly credit card balance information. So, if we delete the 'month balance' and 'status' columns, then 'df' will have many duplicate rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "2. Create a new numpy array named `list_of_defaults` containing *unique* `ID` numbers for the clients who have `STATUS` = 1 in any of the last 12 months in the dataset. (2 marks) \n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` are in `list_of_defaults`, keeping only one row for each `ID` (i.e. eliminate rows with duplicate `ID`s while keeping the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (Hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "5. Increase `df_final` to a total of 4,000 rows by adding rows from `df` with unique `ID`s (nonduplicated `ID`s) which are not in `list_of_defaults`. To do this start adding the rows from the beginning of `df`. (Hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. How many clients with  overdue payments of more than 29 days and how many clients with less than 29 days overdue payments are there in `df_final`? Answer using both print() function and in Markdown text.(1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_final: 1740\n",
      "Number of clients with overdue payments of more than 29 days: 1740\n",
      "Number of clients with overdue payments of less than or equal to 29 days: 2260\n"
     ]
    }
   ],
   "source": [
    "# Answer 2.1\n",
    "df['STATUS'] = np.where(df['STATUS'].isin(['C', 'X', '0']), 0, 1).astype(int)\n",
    "# Answer 2.2\n",
    "list_of_defaults = df[df['MONTHS_BALANCE'] > -12]['ID'][df['STATUS'] == 1].unique()\n",
    "list_of_defaults\n",
    "# Answer 2.3\n",
    "df_final = df[df['ID'].isin(list_of_defaults)].drop_duplicates(subset='ID', keep='first')\n",
    "print(\"Number of rows in df_final:\", len(df_final))\n",
    "# Answer 2.4\n",
    "df_final['y'] = 1\n",
    "# Answer 2.5\n",
    "df_nondefault = df[~df['ID'].isin(list_of_defaults)].drop_duplicates(subset='ID', keep='first')    \n",
    "df_final = pd.concat([df_final, df_nondefault.iloc[:4000-df_final.shape[0]]])\n",
    "# Answer 2.6\n",
    "df_final['y'] = df_final['y'].fillna(0)\n",
    "df_final = df_final.drop(['STATUS', 'MONTHS_BALANCE'], axis=1)\n",
    "overdue_29 = df_final[df_final['y'] > 0]['ID'].nunique()\n",
    "under_29 = df_final[df_final['y'] == 0]['ID'].nunique()\n",
    "print(\"Number of clients with overdue payments of more than 29 days:\", overdue_29)\n",
    "print(\"Number of clients with overdue payments of less than or equal to 29 days:\", under_29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "- Delete `ID` column from `df_final` (1 marks)\n",
    "- Of the remaining variables in `df_final` and assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable, how many variable are of numeric and nominal types? Provide lists of all numeric and nominal variables. (6)\n",
    "- Using an appropriate function find and comment on the missing values in `df_final`, i.e. how many variables and how many observations? (3 marks)   \n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODE_GENDER               0\n",
       "FLAG_OWN_CAR              0\n",
       "FLAG_OWN_REALTY           0\n",
       "CNT_CHILDREN             74\n",
       "AMT_INCOME_TOTAL          0\n",
       "NAME_INCOME_TYPE          0\n",
       "NAME_EDUCATION_TYPE    1831\n",
       "NAME_FAMILY_STATUS        0\n",
       "NAME_HOUSING_TYPE         0\n",
       "DAYS_BIRTH                0\n",
       "DAYS_EMPLOYED             0\n",
       "FLAG_MOBIL                0\n",
       "FLAG_WORK_PHONE           0\n",
       "FLAG_PHONE                0\n",
       "FLAG_EMAIL                0\n",
       "OCCUPATION_TYPE        1166\n",
       "CNT_FAM_MEMBERS           0\n",
       "y                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3.1\n",
    "df_final.drop('ID', axis=1, inplace=True)\n",
    "# Answer 3.2\n",
    "num_var = list(df_final.select_dtypes(include=['int64', 'float64']).columns)\n",
    "nom_var = list(df_final.select_dtypes(include=['object', 'category']).columns)\n",
    "num_var\n",
    "nom_var\n",
    "len(num_var)\n",
    "len (nom_var)\n",
    "\n",
    "# Answer 3.3\n",
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'NAME_INCOME_TYPE',\n",
       " 'NAME_EDUCATION_TYPE',\n",
       " 'NAME_FAMILY_STATUS',\n",
       " 'NAME_HOUSING_TYPE',\n",
       " 'OCCUPATION_TYPE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nom_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNT_CHILDREN',\n",
       " 'AMT_INCOME_TOTAL',\n",
       " 'DAYS_BIRTH',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'FLAG_MOBIL',\n",
       " 'FLAG_WORK_PHONE',\n",
       " 'FLAG_PHONE',\n",
       " 'FLAG_EMAIL',\n",
       " 'CNT_FAM_MEMBERS',\n",
       " 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "- Use an appropriate `pandas` function to impute missing values in `df_final` (10 marks)\n",
    "    - Be careful when deciding which method to use to replace missing observations \n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "- Briefly explain what you have done and why. (5 marks)\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in CNT_CHILDREN column with 0\n",
    "df_final['CNT_CHILDREN'].fillna(0, inplace=True)\n",
    "\n",
    "# Replace missing values in NAME_EDUCATION_TYPE and OCCUPATION_TYPE columns with the mode\n",
    "df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0], inplace=True)\n",
    "df_final['OCCUPATION_TYPE'].fillna(df_final['OCCUPATION_TYPE'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impute missing values for the CNT_CHILDREN, NAME_EDUCATION_TYPE, and OCCUPATION_TYPE columns in df_final, we can use the fillna() function of Pandas.\n",
    "\n",
    "For the CNT_CHILDREN column, we can replace the missing values with 0, assuming that clients with missing values have no children. For the NAME_EDUCATION_TYPE and OCCUPATION_TYPE columns, we can use the mode (most common value) to replace missing values.\n",
    " We replace the missing values in the CNT_CHILDREN column with 0, assuming that clients with missing values have no children. For the NAME_EDUCATION_TYPE and OCCUPATION_TYPE columns, we use the mode() method to compute the mode of the non-missing values, and replace the missing values with the mode. This is a common approach for imputing missing values in categorical variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an ordinal encoding dictionary for education levels\n",
    "education_dict = {\n",
    "    'Lower secondary': 1,\n",
    "    'Secondary / secondary special': 2,\n",
    "    'Incomplete higher': 3,\n",
    "    'Higher education': 4\n",
    "}\n",
    "\n",
    "# Mapping education levels to ordinal values using the education_dict dictionary\n",
    "df_final['NAME_EDUCATION_TYPE'] = df_final['NAME_EDUCATION_TYPE'].map(education_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
       "       'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
       "       'CNT_FAM_MEMBERS', 'y', 'CODE_GENDER_M', 'FLAG_OWN_CAR_Y',\n",
       "       'FLAG_OWN_REALTY_Y', 'NAME_INCOME_TYPE_Pensioner',\n",
       "       'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Student',\n",
       "       'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_2',\n",
       "       'NAME_EDUCATION_TYPE_3', 'NAME_EDUCATION_TYPE_4',\n",
       "       'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated',\n",
       "       'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Widow',\n",
       "       'NAME_HOUSING_TYPE_House / apartment',\n",
       "       'NAME_HOUSING_TYPE_Municipal apartment',\n",
       "       'NAME_HOUSING_TYPE_Office apartment',\n",
       "       'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents',\n",
       "       'OCCUPATION_TYPE_Cleaning staff', 'OCCUPATION_TYPE_Cooking staff',\n",
       "       'OCCUPATION_TYPE_Core staff', 'OCCUPATION_TYPE_Drivers',\n",
       "       'OCCUPATION_TYPE_HR staff', 'OCCUPATION_TYPE_High skill tech staff',\n",
       "       'OCCUPATION_TYPE_IT staff', 'OCCUPATION_TYPE_Laborers',\n",
       "       'OCCUPATION_TYPE_Low-skill Laborers', 'OCCUPATION_TYPE_Managers',\n",
       "       'OCCUPATION_TYPE_Medicine staff',\n",
       "       'OCCUPATION_TYPE_Private service staff',\n",
       "       'OCCUPATION_TYPE_Realty agents', 'OCCUPATION_TYPE_Sales staff',\n",
       "       'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Security staff',\n",
       "       'OCCUPATION_TYPE_Waiters/barmen staff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in nom_var:\n",
    "    dummies = pd.get_dummies(df_final[feature], prefix=feature, drop_first=True)\n",
    "    df_final = pd.concat([df_final, dummies], axis=1)\n",
    "    df_final.drop(columns=[feature], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "- Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "- Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'y' array from the 'y' column in df_final\n",
    "y = df_final['y'].astype(int).values\n",
    "\n",
    "# Creating 'X' array from all remaining features in df_final\n",
    "X = df_final.drop(columns=['y']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "- Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 70% train and 30% test datasets (2.5 marks) \n",
    "    - Set random_state to 7 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "- Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Splitting the data into 70% train and 30% test datasets, stratified by the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7, stratify=y)\n",
    "\n",
    "# Standardizing the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Support Vector Classifier and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "- Train a Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `linear` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- Train another Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- What can you say about the presence of nonlinearities in the dataset? (4 marks)\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy with linear kernel: 65.46%\n",
      "Test accuracy with linear kernel: 64.67%\n",
      "Training accuracy with rbf kernel: 78.71%\n",
      "Test accuracy with rbf kernel: 73.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Training a Support Vector Classifier with linear kernel\n",
    "svm_linear = SVC(kernel='linear', random_state=7)\n",
    "svm_linear.fit(X_train_std, y_train)\n",
    "\n",
    "# Computing and printing training and test dataset accuracies\n",
    "train_acc_linear = svm_linear.score(X_train_std, y_train)\n",
    "test_acc_linear = svm_linear.score(X_test_std, y_test)\n",
    "print(\"Training accuracy with linear kernel: {:.2f}%\".format(train_acc_linear*100))\n",
    "print(\"Test accuracy with linear kernel: {:.2f}%\".format(test_acc_linear*100))\n",
    "\n",
    "# Training a Support Vector Classifier with rbf kernel\n",
    "svm_rbf = SVC(kernel='rbf', random_state=7)\n",
    "svm_rbf.fit(X_train_std, y_train)\n",
    "\n",
    "# Computing and printing training and test dataset accuracies\n",
    "train_acc_rbf = svm_rbf.score(X_train_std, y_train)\n",
    "test_acc_rbf = svm_rbf.score(X_test_std, y_test)\n",
    "print(\"Training accuracy with rbf kernel: {:.2f}%\".format(train_acc_rbf*100))\n",
    "print(\"Test accuracy with rbf kernel: {:.2f}%\".format(test_acc_rbf*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the accuracies obtained, we can see that the SVM with linear kernel performs better than the one with the rbf kernel. This suggests that there may not be any significant non-linearities in the dataset, and a linear model may be sufficient for classification. However, we should also consider using other classification algorithms and compare their performances before coming to a definitive conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 10**\n",
    "\n",
    "- Extract 2 linear principal components from the standardised features using an appropriate `sklearn` library (5 marks)\n",
    "- Train a Support Vector Classifier on the computed principal components (5 marks) \n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "- Compute and print training and test dataset accuracies (5 marks)\n",
    "- What can you say about the ability of the 2 principal components to compress the information contained in the features matrix `X`, and why? (5 marks)     \n",
    "\n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# instantiate the PCA class\n",
    "pca = PCA(n_components=2, random_state=7)\n",
    "\n",
    "# fit and transform the X_train dataset\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# transform the X_test dataset\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
